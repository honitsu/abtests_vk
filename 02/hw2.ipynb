{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66c26f02",
   "metadata": {},
   "source": [
    "В этом задании вам необходимо будет:\n",
    "\n",
    "1. Реализовать формулу подсчета длительности теста, сравнить ее с онлайн калькуляторами (например https://mindbox.ru/tools/ab-test-calculator/ ). При сравнении оценить мощность критерия при указанном изменении и рассчитанном количестве наблюдений в выборке. \n",
    "\n",
    "2. Реализовать метод линеаризации. Проверить для него корректность и мощность. Входные данные - синтетически сгенерированные.\n",
    "\n",
    "3. Реализовать метод CUPED. Проверить для него корректность и мощность. Данные на этапе до A/B теста необходимо сгенерировать один раз, далее синтетически генерировать только часть, связанную с проведением A/B-теста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "228dd755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.power import tt_ind_solve_power, zt_ind_solve_power\n",
    "from statsmodels.stats.proportion import proportion_effectsize\n",
    "from statsmodels.stats.meta_analysis import effectsize_smd\n",
    "from typing import Union\n",
    "from scipy import stats\n",
    "from math import asin\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3691f2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Необходимый размер выборки для каждой группы: 29497\n"
     ]
    }
   ],
   "source": [
    "def calculate_sample_size_per_group(alpha, beta, p1, p2):\n",
    "    \"\"\"\n",
    "    Рассчитываем размер выборки для каждой группы A/B теста.\n",
    "    \n",
    "    :param alpha: Уровень значимости (обычно 0.05)\n",
    "    :param beta: Вероятность ошибки второго рода, 1 - мощность\n",
    "    :param p1: Базовый уровень конверсии в контрольной группе\n",
    "    :param p2: Ожидаемый уровень конверсии в экспериментальной группе после изменений\n",
    "    :return: Размер выборки для каждой группы\n",
    "    \"\"\"\n",
    "    # Стандартное отклонение для двух пропорций\n",
    "    sigma = lambda p: np.sqrt(2 * p * (1 - p))\n",
    "    \n",
    "    # Стандартная ошибка разности между двумя пропорциями\n",
    "    se = lambda p1, p2: np.sqrt(sigma(p1)**2 + sigma(p2)**2)\n",
    "    \n",
    "    # Рассчитываем Z-значения для альфа и бета\n",
    "    z_alpha = stats.norm.ppf(1 - alpha / 2)\n",
    "    z_beta = stats.norm.ppf(1 - beta)\n",
    "    \n",
    "    # Размер выборки для каждой группы\n",
    "    n = ((z_alpha + z_beta) * se(p1, p2))**2 / (p2 - p1)**2\n",
    "    return int(np.ceil(n))  # Округляем вверх до целого числа\n",
    "\n",
    "# Зададим параметры теста\n",
    "alpha = 0.05  # Уровень значимости 5%\n",
    "power = 0.8   # Мощность 80%\n",
    "beta = 1 - power  # Ошибка II рода\n",
    "\n",
    "# Базовый уровень конверсии и ожидаемое улучшение\n",
    "base_conversion_rate = 0.10  # 10%\n",
    "minimum_detectable_effect = 0.01  # Ожидаемое улучшение на 1%\n",
    "\n",
    "# Ожидаемый уровень конверсии после внедрения изменений\n",
    "expected_conversion_rate = base_conversion_rate + minimum_detectable_effect\n",
    "\n",
    "# Рассчитаем размер выборки для каждой группы\n",
    "sample_size = calculate_sample_size_per_group(alpha, beta, base_conversion_rate, expected_conversion_rate)\n",
    "print(f\"Необходимый размер выборки для каждой группы: {sample_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abeb387f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Рассчитанная мощность: 0.9774\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.power import NormalIndPower\n",
    "from statsmodels.stats.proportion import proportion_effectsize\n",
    "\n",
    "# Рассчитаем мощность критерия\n",
    "effect_size = proportion_effectsize(base_conversion_rate, expected_conversion_rate)\n",
    "power_analysis = NormalIndPower()\n",
    "power_result = power_analysis.solve_power(effect_size=effect_size, \n",
    "                                          nobs1=sample_size, \n",
    "                                          alpha=alpha)\n",
    "\n",
    "print(f\"Рассчитанная мощность: {power_result:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "401fb1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер выборки для каждой группы: 3841.0\n",
      "T-statistic: nan, P-value: nan\n",
      "CUPED T-statistic: 0.45089468694502255, P-value: 0.652078182563837\n"
     ]
    }
   ],
   "source": [
    "#import scipy.stats as stats\n",
    "np.seterr(divide='ignore')\n",
    "\n",
    "def calculate_sample_size(base_conversion_rate, minimum_detectable_effect, alpha=0.05, power=0.8):\n",
    "    \"\"\"\n",
    "    Расчет размера выборки на основе базовой конверсии, минимального обнаруживаемого эффекта,\n",
    "    уровня значимости (alpha) и мощности критерия (power).\n",
    "    \"\"\"\n",
    "    # Значение Z-критерия для заданного уровня значимости\n",
    "    z_alpha = stats.norm.ppf(1 - alpha/2)\n",
    "    # Значение Z-критерия для заданной мощности\n",
    "    z_power = stats.norm.ppf(power)\n",
    "    \n",
    "    # Преобразование базовой конверсии и МДЭ в пропорции\n",
    "    p1 = base_conversion_rate\n",
    "    p2 = base_conversion_rate + minimum_detectable_effect\n",
    "    p_combined = (p1 + p2) / 2\n",
    "    \n",
    "    # Расчет размера выборки\n",
    "    sample_size = (z_alpha*np.sqrt(2*p_combined*(1-p_combined)) + z_power*np.sqrt(p1*(1-p1)+p2*(1-p2)))**2 / minimum_detectable_effect**2\n",
    "    return np.ceil(sample_size)  # Округляем в большую сторону\n",
    "\n",
    "# Тестирование\n",
    "base_conv_rate = 0.1  # Базовая конверсия\n",
    "min_det_effect = 0.02  # Минимальный обнаруживаемый эффект (например, увеличение на 2%)\n",
    "sample_size = calculate_sample_size(base_conv_rate, min_det_effect)\n",
    "print(f\"Размер выборки для каждой группы: {sample_size}\")\n",
    "\n",
    "# Пример функции линеаризации для пропорций\n",
    "def linearize_proportions(data):\n",
    "    \"\"\"\n",
    "    Линеаризация массива данных с пропорциями путем использования логарифмического преобразования.\n",
    "    \"\"\"\n",
    "    return np.log(data / (1 - data))\n",
    "\n",
    "# Генерация синтетических данных\n",
    "np.random.seed(42)  # Устанавливаем seed для воспроизводимости\n",
    "group_a = np.random.binomial(1, base_conv_rate, int(sample_size))\n",
    "group_b = np.random.binomial(1, base_conv_rate + min_det_effect, int(sample_size))\n",
    "\n",
    "# Линеаризация данных\n",
    "linearized_a = linearize_proportions(group_a)\n",
    "linearized_b = linearize_proportions(group_b)\n",
    "\n",
    "# Проверка корректности и мощности можно провести через t-тест на линеаризированных данных\n",
    "t_stat, p_value = stats.ttest_ind(linearized_a, linearized_b)\n",
    "print(f\"T-statistic: {t_stat}, P-value: {p_value}\")\n",
    "\n",
    "# Если P-value < alpha, мы отвергаем нулевую гипотезу о равенстве средних в двух группах.\n",
    "\n",
    "def generate_pre_test_data(n, mean, std):\n",
    "    \"\"\"\n",
    "    Генерация предтестовых данных, которые имитируют метрики до проведения A/B-теста.\n",
    "    \"\"\"\n",
    "    return np.random.normal(mean, std, n)\n",
    "\n",
    "def apply_cuped(post_test_data, pre_test_data, covariate_mean):\n",
    "    \"\"\"\n",
    "    Применение CUPED к посттестовым данным, используя предтестовые данные.\n",
    "    \"\"\"\n",
    "    theta = np.cov(post_test_data, pre_test_data)[0][1] / np.var(pre_test_data)\n",
    "    cuped_scores = post_test_data - theta * (pre_test_data - covariate_mean)\n",
    "    return cuped_scores\n",
    "\n",
    "# Генерация предтестовых данных\n",
    "pre_test_mean = 100  # Среднее значение метрики до теста\n",
    "pre_test_std = 15    # Стандартное отклонение метрики до теста\n",
    "pre_test_data = generate_pre_test_data(int(2*sample_size), pre_test_mean, pre_test_std)\n",
    "\n",
    "# Генерация посттестовых данных для групп A и B\n",
    "post_test_data_a = pre_test_data[:int(sample_size)] + np.random.normal(\n",
    "    0, pre_test_std * 0.1, int(sample_size))\n",
    "post_test_data_b = pre_test_data[int(sample_size):] + np.random.normal(\n",
    "    min_det_effect, pre_test_std * 0.1, int(sample_size))\n",
    "\n",
    "# Применение CUPED\n",
    "cuped_scores_a = apply_cuped(post_test_data_a, pre_test_data[:int(sample_size)], pre_test_mean)\n",
    "cuped_scores_b = apply_cuped(post_test_data_b, pre_test_data[int(sample_size):], pre_test_mean)\n",
    "# Анализ CUPED-трансформированных данных\n",
    "t_stat_cuped, p_value_cuped = stats.ttest_ind(cuped_scores_a, cuped_scores_b)\n",
    "print(f\"CUPED T-statistic: {t_stat_cuped}, P-value: {p_value_cuped}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091810a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
